{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laporan Proyek Machine Learning - Dion Prayoga"
      ],
      "metadata": {
        "id": "cXpt4EwtEp6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Domain Proyek\n",
        "\n",
        "Kesehatan merupakan sektor penting dalam kehidupan manusia. Deteksi dini terhadap penyakit kronis seperti diabetes sangat diperlukan untuk meningkatkan kualitas hidup pasien. Berdasarkan laporan WHO tahun 2023, lebih dari 422 juta orang di dunia hidup dengan diabetes, dan angka ini terus meningkat setiap tahunnya [1]. Tantangan utama dalam mendeteksi diabetes adalah gejala yang sering kali tidak tampak secara signifikan pada tahap awal. Oleh karena itu, pendekatan berbasis data melalui machine learning dapat digunakan untuk membantu diagnosis awal diabetes secara otomatis dan akurat.\n",
        "\n",
        "[1] World Health Organization. (2023). Diabetes. [Online]. Available: https://www.who.int/news-room/fact-sheets/detail/diabetes\n",
        "\n"
      ],
      "metadata": {
        "id": "hDvSBgxKs0Z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Business Understanding\n",
        "\n",
        "###Problem Statements\n",
        "\n",
        "1. Bagaimana cara memprediksi apakah seseorang menderita diabetes berdasarkan data pemeriksaan medis?\n",
        "\n",
        "2. Bagaimana performa beberapa algoritma klasifikasi populer seperti Decision Tree dan Random Forest dalam mendeteksi diabetes?\n",
        "\n",
        "###Goals\n",
        "\n",
        "1. Mengembangkan model klasifikasi untuk mendeteksi diabetes menggunakan dataset medis.\n",
        "\n",
        "2. Membandingkan performa dua algoritma klasifikasi (Decision Tree dan Random Forest) untuk menentukan model terbaik berdasarkan metrik evaluasi.\n",
        "\n",
        "###Solution Statements\n",
        "\n",
        "1. Menggunakan algoritma Decision Tree dan Random Forest untuk membangun model prediksi.\n",
        "\n",
        "2. Melakukan hyperparameter tuning pada masing-masing model untuk meningkatkan performa.\n",
        "\n",
        "3. Menggunakan metrik akurasi, precision, recall, dan F1-score untuk mengevaluasi model."
      ],
      "metadata": {
        "id": "S1CGGKapthSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Understanding\n",
        "\n",
        "Dataset yang digunakan adalah Pima Indians Diabetes Database yang tersedia secara publik melalui Kaggle:\n",
        "\n",
        "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database.\n",
        "\n",
        "Dataset ini memiliki 768 data sampel dengan 8 fitur input dan 1 label output.\n",
        "\n",
        "###Variabel-Variabel\n",
        "\n",
        "Berikut adalah deskripsi variabel yang terdapat dalam dataset:\n",
        "\n",
        "- Pregnancies: Jumlah kehamilan\n",
        "- Glucose: Kadar glukosa darah\n",
        "- BloodPressure: Tekanan darah diastolik (mm Hg)\n",
        "- SkinThickness: Ketebalan lipatan kulit triceps (mm)\n",
        "- Insulin: Level insulin serum (mu U/ml)\n",
        "- BMI: Indeks massa tubuh (kg/m²)\n",
        "- DiabetesPedigreeFunction: Riwayat keluarga diabetes\n",
        "- Age: Usia (tahun)\n",
        "- Outcome: Label target (0 = Tidak diabetes, 1 = Diabetes)\n",
        "\n",
        "###Exploratory Data Analysis (EDA) Singkat\n",
        "\n",
        "- Distribusi Outcome: Terdapat 500 sampel dengan Outcome 0 (tidak diabetes) dan 268 sampel dengan Outcome 1 (diabetes). Ini menunjukkan adanya ketidakseimbangan kelas (class imbalance) yang perlu diperhatikan dalam evaluasi model.\n",
        "- Nilai 0 yang Tidak Valid: Beberapa fitur seperti Glucose, BloodPressure, SkinThickness, Insulin, dan BMI memiliki nilai 0 yang secara medis tidak mungkin (misalnya, BMI = 0). Nilai-nilai ini akan dianggap sebagai missing values dan ditangani pada tahap Data Preparation."
      ],
      "metadata": {
        "id": "80h0ZnRXuOcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Memuat dataset\n",
        "df = pd.read_csv('diabetes.csv') # Pastikan nama file sesuai\n",
        "\n",
        "# Tampilkan 5 baris pertama\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GctgmEMG76U",
        "outputId": "1ffc9464-d9c9-4ba5-aae2-9f6ce3de84ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat tipe data dan jumlah non-null tiap kolom\n",
        "df.info()\n",
        "\n",
        "# Melihat semua nama kolom (variabel) dalam dataset\n",
        "print(\"\\nNama-nama kolom:\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kN4-A_pG_a9",
        "outputId": "c3d249ee-e479-4535-ce1f-167229f4afbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "\n",
            "Nama-nama kolom:\n",
            "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
            "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation\n",
        "\n",
        "Langkah-langkah data preparation bertujuan untuk membersihkan dan mentransformasi data sehingga siap digunakan untuk pelatihan model.\n",
        "\n",
        "###Mengatasi Nilai 0 yang Tidak Valid\n",
        "\n",
        "Nilai 0 pada fitur-fitur seperti Glucose, BloodPressure, SkinThickness, Insulin, dan BMI akan diganti dengan nilai median dari masing-masing fitur. Pemilihan median lebih robust terhadap outlier dibandingkan mean."
      ],
      "metadata": {
        "id": "-_RJ_QAUvDkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengganti nilai 0 yang tidak valid dengan NaN\n",
        "for col in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:\n",
        "    df[col] = df[col].replace(0, np.nan)\n",
        "\n",
        "# Mengisi nilai NaN dengan median masing-masing kolom\n",
        "for col in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:\n",
        "    median_val = df[col].median()\n",
        "    df[col].fillna(median_val, inplace=True)\n",
        "\n",
        "# Memisahkan fitur (X) dan target (y)\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWwBFBPduko3",
        "outputId": "67c21cf1-b78a-41fb-c432-49b3f6261e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-371157218661>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(median_val, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Normalisasi Data\n",
        "\n",
        "Normalisasi data menggunakan MinMaxScaler akan diterapkan untuk menyetarakan skala fitur. Hal ini penting untuk algoritma yang sensitif terhadap skala fitur, meskipun untuk Decision Tree dan Random Forest dampaknya tidak terlalu signifikan. Namun, ini praktik yang baik untuk menjaga konsistensi dan adaptasi jika model lain digunakan."
      ],
      "metadata": {
        "id": "iUvzs3YWD0la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalisasi data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns) # Opsional: mengembalikan ke DataFrame untuk memudahkan inspeksi"
      ],
      "metadata": {
        "id": "sruj1uzuD8IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Memisahkan Data Training dan Testing\n",
        "\n",
        "Data akan dibagi menjadi training set dan testing set dengan rasio 80:20 menggunakan train_test_split. Penggunaan random_state akan memastikan reproduktibilitas hasil pembagian data."
      ],
      "metadata": {
        "id": "UqY5y4GiD8Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Memisahkan data menjadi training dan testing set (80:20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Ukuran X_train: {X_train.shape}\")\n",
        "print(f\"Ukuran X_test: {X_test.shape}\")\n",
        "print(f\"Ukuran y_train: {y_train.shape}\")\n",
        "print(f\"Ukuran y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2uOqllmEFBI",
        "outputId": "160fc14e-a034-4629-d0ea-5ebf4cf8deb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ukuran X_train: (614, 8)\n",
            "Ukuran X_test: (154, 8)\n",
            "Ukuran y_train: (614,)\n",
            "Ukuran y_test: (154,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling\n",
        "\n",
        "Tahapan ini membahas mengenai model machine learning yang digunakan untuk menyelesaikan permasalahan prediksi diabetes. Kami akan menjelaskan tahapan pemodelan, cara kerja algoritma, serta parameter yang digunakan pada proses pemodelan.\n",
        "\n",
        "###Algoritma 1: Decision Tree\n",
        "\n",
        "Decision Tree adalah algoritma machine learning non-parametrik yang kuat dan mudah diinterpretasi, digunakan untuk tugas klasifikasi dan regresi. Cara kerjanya menyerupai pohon keputusan (if-else) yang kita buat secara manual. Model ini belajar dengan membagi data menjadi subset-subset yang lebih kecil berdasarkan fitur-fitur input. Pada setiap \"node\" dalam pohon, algoritma memilih fitur dan threshold yang paling baik memisahkan data ke dalam kelas outcome yang berbeda. Proses pembagian ini berlanjut secara rekursif hingga kriteria berhenti terpenuhi (misalnya, mencapai kedalaman maksimum atau jumlah sampel minimum pada sebuah node). Prediksi untuk data baru dilakukan dengan menelusuri pohon dari \"akar\" hingga \"daun\" berdasarkan nilai fitur data tersebut, dan outcome dari daun yang dicapai adalah prediksinya.\n",
        "\n",
        "####Kelebihan Decision Tree:\n",
        "\n",
        "- Mudah Diinterpretasi: Strukturnya yang seperti pohon membuatnya mudah dipahami dan divisualisasikan.\n",
        "- Tidak Membutuhkan Normalisasi/Skala: Tidak sensitif terhadap penskalaan fitur.\n",
        "- Mampu Menangani Data Kategorikal dan Numerik: Dapat bekerja dengan berbagai jenis data.\n",
        "\n",
        "####Kekurangan Decision Tree:\n",
        "\n",
        "- Cenderung Overfitting: Terutama pada pohon yang dalam, mudah beradaptasi terlalu spesifik pada data pelatihan.\n",
        "- Tidak Robust Terhadap Perubahan Kecil: Sedikit perubahan pada data dapat menghasilkan pohon yang sangat berbeda.\n",
        "- Bias Terhadap Kelas Dominan: Jika ada ketidakseimbangan kelas, cenderung bias ke kelas mayoritas.\n",
        "\n",
        "####Proses Pemodelan dan Hyperparameter Tuning\n",
        "\n",
        "Untuk mendapatkan performa terbaik dari Decision Tree, kami melakukan hyperparameter tuning menggunakan GridSearchCV. Proses ini mencari kombinasi hyperparameter yang optimal dengan mengevaluasi model pada berbagai kombinasi parameter melalui validasi silang (cross-validation).\n",
        "\n",
        "####Hyperparameter yang di-tuning:\n",
        "\n",
        "- max_depth: Kedalaman maksimum pohon. Ini mengontrol kompleksitas model dan membantu mencegah overfitting dengan membatasi seberapa jauh pohon dapat tumbuh.\n",
        "- min_samples_split: Jumlah minimum sampel yang dibutuhkan untuk membagi sebuah node. Jika sebuah node memiliki sampel kurang dari nilai ini, ia tidak akan dibagi lebih lanjut."
      ],
      "metadata": {
        "id": "zdGxxdqVEIMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definisi model Decision Tree\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Grid hyperparameter untuk Decision Tree\n",
        "param_grid_dt = {\n",
        "    'max_depth': [4, 6, 8, 10, None], # None berarti tidak ada batasan kedalaman\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Melakukan GridSearchCV\n",
        "grid_search_dt = GridSearchCV(dt_classifier, param_grid_dt, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "grid_search_dt.fit(X_train, y_train)\n",
        "\n",
        "# Model Decision Tree terbaik\n",
        "best_dt_model = grid_search_dt.best_estimator_\n",
        "print(f\"Best hyperparameters for Decision Tree: {grid_search_dt.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll7TA_YSEUHm",
        "outputId": "d960f46c-cfb6-4bf7-cedf-61f567a36518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "Best hyperparameters for Decision Tree: {'max_depth': 4, 'min_samples_split': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Parameter Terbaik untuk Decision Tree:\n",
        "Berdasarkan hasil GridSearchCV, parameter terbaik yang didapatkan untuk Decision Tree adalah max_depth=4 dan min_samples_split=2. Nilai-nilai ini akan digunakan oleh best_dt_model untuk membuat prediksi."
      ],
      "metadata": {
        "id": "SWH6Y-MQ6ycZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Algoritma 2: Random Forest\n",
        "\n",
        "Random Forest adalah algoritma ensemble learning yang membangun banyak Decision Tree (disebut juga \"pohon keputusan\") secara independen dan paralel. Ide dasarnya adalah bahwa banyak pohon yang \"agak benar\" dan beragam akan secara kolektif menghasilkan prediksi yang lebih akurat dan stabil dibandingkan satu pohon keputusan tunggal. Setiap pohon dalam forest dilatih pada subset data pelatihan yang di-bootstrap (dengan penggantian) dan hanya menggunakan subset fitur acak pada setiap node. Ketika melakukan prediksi, Random Forest mengumpulkan voting dari semua pohon (untuk klasifikasi) atau merata-ratakan prediksi (untuk regresi) untuk menghasilkan outcome akhir. Proses ini membantu mengurangi masalah overfitting yang sering terjadi pada Decision Tree tunggal dan meningkatkan generalisasi model.\n",
        "\n",
        "####Kelebihan Random Forest:\n",
        "\n",
        "- Akurasi Tinggi: Umumnya memberikan akurasi yang sangat baik dan robust.\n",
        "- Mengatasi Overfitting: Karena merupakan algoritma ensemble, sangat efektif dalam mengurangi overfitting dibandingkan Decision Tree tunggal.\n",
        "- Dapat Menangani Banyak Fitur: Mampu bekerja dengan dataset yang memiliki banyak fitur.\n",
        "- Kurang Sensitif Terhadap Outlier: Lebih robust terhadap outlier dan missing values.\n",
        "\n",
        "####Kekurangan Random Forest:\n",
        "\n",
        "- Kurang Dapat Diinterpretasi: Dibandingkan Decision Tree tunggal, Random Forest lebih sulit untuk diinterpretasi karena melibatkan banyak pohon.\n",
        "- Membutuhkan Sumber Daya Komputasi Lebih Besar: Pelatihan banyak pohon membutuhkan lebih banyak waktu dan memori.\n",
        "\n",
        "####Proses Pemodelan dan Hyperparameter Tuning\n",
        "\n",
        "Sama seperti Decision Tree, kami juga melakukan hyperparameter tuning untuk Random Forest menggunakan GridSearchCV guna menemukan konfigurasi parameter terbaik yang mengoptimalkan performa model.\n",
        "\n",
        "####Hyperparameter yang di-tuning:\n",
        "\n",
        "- n_estimators: Jumlah pohon (Decision Tree) dalam forest. Semakin banyak pohon, semakin stabil prediksinya, namun komputasi juga akan meningkat.\n",
        "- max_depth: Kedalaman maksimum setiap pohon dalam forest. Membatasi pertumbuhan pohon individu untuk mengontrol kompleksitas."
      ],
      "metadata": {
        "id": "eY24gWeuEYrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Definisi model Random Forest\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Grid hyperparameter untuk Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'max_depth': [4, 6, 8, 10, None]\n",
        "}\n",
        "\n",
        "# Melakukan GridSearchCV\n",
        "grid_search_rf = GridSearchCV(rf_classifier, param_grid_rf, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Model Random Forest terbaik\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "print(f\"Best hyperparameters for Random Forest: {grid_search_rf.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMHwptPREjDV",
        "outputId": "3b45e2d5-d5b9-4657-c5d3-fb527b23ea77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best hyperparameters for Random Forest: {'max_depth': None, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Parameter Terbaik untuk Random Forest:\n",
        "\n",
        "Berdasarkan hasil GridSearchCV, parameter terbaik yang didapatkan untuk Random Forest adalah n_estimators=100 dan max_depth=None. Nilai-nilai ini akan digunakan oleh best_rf_model untuk membuat prediksi."
      ],
      "metadata": {
        "id": "SwKcK4mS7agc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation\n",
        "\n",
        "Pada bagian ini, kami akan menyebutkan metrik evaluasi yang digunakan dan menjelaskan hasil proyek berdasarkan metrik-metrik tersebut.\n",
        "\n",
        "###Metrik evaluasi yang Digunakan\n",
        "\n",
        "Dalam proyek klasifikasi deteksi diabetes ini, kami menggunakan beberapa metrik evaluasi untuk mendapatkan gambaran yang komprehensif mengenai performa model, mengingat pentingnya identifikasi kasus positif dan negatif:\n",
        "\n",
        "- Akurasi (Accuracy): Mengukur proporsi total prediksi yang benar (baik positif maupun negatif). Ini adalah metrik yang intuitif dan sering digunakan, namun bisa menyesatkan pada dataset dengan class imbalance. Formula: Accuracy= TP+TN/TP+TN+FP+FN\n",
        "\n",
        "- Precision: Mengukur proporsi prediksi positif yang sebenarnya positif. Ini penting ketika biaya false positives (salah mendiagnosis orang sehat sebagai penderita diabetes) sangat tinggi. Formula: Precision=\n",
        "TP+FP\n",
        "TP\n",
        "\n",
        "- Recall (Sensitivity): Mengukur proporsi kasus positif sebenarnya yang berhasil dideteksi oleh model. Ini sangat krusial ketika biaya false negatives (melewatkan diagnosis diabetes pada penderita sebenarnya) sangat tinggi, seperti dalam aplikasi medis. Formula: Recall= TP/TP+FN\n",
        "\n",
        "- F1 Score: Merupakan rata-rata harmonik dari precision dan recall. Metrik ini sangat berguna ketika ada ketidakseimbangan kelas dan kita ingin keseimbangan antara precision dan recall, bukan hanya salah satunya. Formula: F1Score=2× (Precision×Recall/Precision+Recall)\n",
        "\n",
        "Dimana:\n",
        "\n",
        "- TP (True Positive): Jumlah kasus diabetes yang diprediksi benar sebagai diabetes.\n",
        "- TN (True Negative): Jumlah kasus non-diabetes yang diprediksi benar sebagai non-diabetes.\n",
        "- FP (False Positive): Jumlah kasus non-diabetes yang salah diprediksi sebagai diabetes.\n",
        "- FN (False Negative): Jumlah kasus diabetes yang salah diprediksi sebagai non-diabetes."
      ],
      "metadata": {
        "id": "mF1XDzoFEqHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hasil Proyek Berdasarkan Metrik Evaluasi\n",
        "\n",
        "Setelah melatih dan menyetel kedua model, kami mengevaluasi performa mereka pada testing set yang belum pernah dilihat model sebelumnya. Berikut adalah hasil evaluasinya:"
      ],
      "metadata": {
        "id": "OCSnCOyp7_30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # <--- BARIS INI YANG PENTING DITAMBAHKAN\n",
        "\n",
        "# Prediksi menggunakan model Decision Tree terbaik\n",
        "y_pred_dt = best_dt_model.predict(X_test)\n",
        "\n",
        "# Evaluasi Decision Tree\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "f1_dt = f1_score(y_test, y_pred_dt)\n",
        "\n",
        "print(\"--- Evaluasi Decision Tree ---\")\n",
        "print(f\"Akurasi: {accuracy_dt:.4f}\")\n",
        "print(f\"Precision: {precision_dt:.4f}\")\n",
        "print(f\"Recall: {recall_dt:.4f}\")\n",
        "print(f\"F1 Score: {f1_dt:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Prediksi menggunakan model Random Forest terbaik\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluasi Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf)\n",
        "recall_rf = recall_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"--- Evaluasi Random Forest ---\")\n",
        "print(f\"Akurasi: {accuracy_rf:.4f}\")\n",
        "print(f\"Precision: {precision_rf:.4f}\")\n",
        "print(f\"Recall: {recall_rf:.4f}\")\n",
        "print(f\"F1 Score: {f1_rf:.4f}\")\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAZHUFE1FigD",
        "outputId": "c31b6915-b141-43fb-d33c-f20c7eb04fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluasi Decision Tree ---\n",
            "Akurasi: 0.7078\n",
            "Precision: 0.5676\n",
            "Recall: 0.7636\n",
            "F1 Score: 0.6512\n",
            "------------------------------\n",
            "--- Evaluasi Random Forest ---\n",
            "Akurasi: 0.7403\n",
            "Precision: 0.6316\n",
            "Recall: 0.6545\n",
            "F1 Score: 0.6429\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analisis Hasil:\n",
        "\n",
        "Dari tabel hasil evaluasi, kita dapat mengamati perbedaan performa yang menarik antara Decision Tree dan Random Forest:\n",
        "\n",
        "- Akurasi: Random Forest menunjukkan akurasi yang lebih tinggi (0.7403) dibandingkan Decision Tree (0.7078). Ini berarti Random Forest secara keseluruhan membuat prediksi benar lebih banyak.\n",
        "- Precision: Random Forest memiliki precision yang lebih baik (0.6316) daripada Decision Tree (0.5676). Ini mengindikasikan bahwa ketika Random Forest memprediksi seseorang menderita diabetes, probabilitas prediksinya benar lebih tinggi. Ini penting untuk meminimalkan false positives, di mana seseorang yang sehat salah didiagnosis diabetes.\n",
        "- Recall: Decision Tree menunjukkan recall yang significantly lebih tinggi (0.7636) dibandingkan Random Forest (0.6545). Ini adalah temuan krusial: Decision Tree lebih baik dalam mengidentifikasi sebagian besar kasus diabetes yang sebenarnya. Dalam konteks deteksi penyakit seperti diabetes, recall yang tinggi sangat penting untuk meminimalkan false negatives (kasus diabetes yang tidak terdeteksi), karena melewatkan diagnosis dapat memiliki konsekuensi kesehatan yang serius.\n",
        "- F1 Score: Decision Tree sedikit lebih unggul dalam F1 Score (0.6512) dibandingkan Random Forest (0.6429). Meskipun selisihnya tipis, F1 Score yang lebih tinggi pada Decision Tree menunjukkan keseimbangan yang sedikit lebih baik antara precision dan recall dalam kasus ini, terutama didorong oleh recall yang sangat tinggi.\n",
        "\n",
        "####Kesimpulan dari Analisis:\n",
        "\n",
        "Pilihan model terbaik sangat bergantung pada prioritas kasus penggunaan. Jika tujuan utamanya adalah untuk meminimalkan false negatives (memastikan semua kasus diabetes terdeteksi, bahkan jika ada beberapa false positives), maka Decision Tree mungkin menjadi pilihan yang lebih unggul karena recall-nya yang tinggi. Ini relevan dalam skenario skrining awal di mana deteksi dini lebih diutamakan.\n",
        "\n",
        "Namun, jika tujuannya adalah untuk memiliki akurasi dan precision yang lebih baik secara keseluruhan (meminimalkan false positives dan false negatives secara seimbang, dengan sedikit fokus pada precision), maka Random Forest akan lebih cocok. Random Forest umumnya lebih robust dan kurang rentan terhadap overfitting dibandingkan Decision Tree tunggal, yang bisa menjadi keuntungan dalam skenario dunia nyata.\n",
        "\n",
        "Dalam proyek ini, dengan mempertimbangkan pentingnya mendeteksi kasus positif (diabetes), Decision Tree menunjukkan keunggulan dalam hal recall, yang sangat berharga dalam konteks medis."
      ],
      "metadata": {
        "id": "PB5b8B1qF1eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kesimpulan\n",
        "\n",
        "Proyek ini berhasil mengembangkan model klasifikasi untuk deteksi diabetes menggunakan dataset Pima Indians Diabetes. Setelah melalui tahapan data preparation yang meliputi penanganan nilai missing dan normalisasi, dua algoritma klasifikasi, Decision Tree dan Random Forest, dilatih dan dievaluasi.\n",
        "\n",
        "Hyperparameter tuning dengan GridSearchCV memainkan peran penting dalam mengoptimalkan performa kedua model. Dari hasil evaluasi, Decision Tree menunjukkan recall yang lebih tinggi, menjadikannya pilihan yang kuat jika prioritas utama adalah mendeteksi sebanyak mungkin kasus diabetes (meminimalkan false negatives). Di sisi lain, Random Forest menawarkan akurasi dan precision yang lebih tinggi, yang bermanfaat jika fokusnya adalah memastikan kebenaran prediksi positif dan mengurangi false positives. Pemilihan model akhir akan bergantung pada prioritas klinis dan dampak dari false positives dan false negatives dalam aplikasi praktis.\n",
        "\n"
      ],
      "metadata": {
        "id": "DhAtbi0uGF9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saran untuk Pengembangan Lebih Lanjut\n",
        "\n",
        "1. Penanganan Class Imbalance Lanjutan: Meskipun F1-score sudah digunakan sebagai metrik yang robust, teknik penanganan class imbalance seperti SMOTE (Synthetic Minority Over-sampling Technique), ADASYN, atau undersampling dapat dieksplorasi lebih lanjut untuk melihat apakah performa model, terutama recall dari Random Forest, dapat ditingkatkan.\n",
        "2. Eksplorasi Algoritma Lain: Mencoba algoritma klasifikasi lain seperti Support Vector Machine (SVM), Logistic Regression, Gradient Boosting Machines (seperti XGBoost, LightGBM), atau bahkan Neural Networks untuk membandingkan performa lebih lanjut dan melihat potensi peningkatan.\n",
        "3. Validasi Eksternal: Menguji model pada dataset diabetes lain yang independen dari sumber atau populasi yang berbeda dapat memberikan validasi yang lebih kuat terhadap generalisasi dan robustness model.\n",
        "4. Interpretasi Model: Menggunakan teknik interpretasi model seperti SHAP values atau LIME akan sangat bermanfaat untuk memahami fitur mana yang paling berpengaruh dalam prediksi diabetes oleh model. Wawasan ini tidak hanya meningkatkan kepercayaan pada model tetapi juga dapat memberikan temuan medis yang berharga bagi para profesional kesehatan.\n",
        "5. Optimasi Threshold: Karena perbedaan recall dan precision yang signifikan, melakukan optimasi threshold klasifikasi (misalnya, pada probabilitas prediksi) dapat membantu menyesuaikan model untuk kebutuhan spesifik, misalnya, untuk mendapatkan recall yang lebih tinggi tanpa mengorbankan precision secara drastis, atau sebaliknya."
      ],
      "metadata": {
        "id": "nNDgDUIlGJ50"
      }
    }
  ]
}